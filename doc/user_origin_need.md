# 原始用户需求描述


1.  **0.1 用户初始需求接收Agent (User Initial Request Receiver):**
    *   **任务:**
        1.  接收用户输入的原始自然语言需求文本。
        2.  将原始文本一字不差地记录下来。
        3.  将记录的原始需求文本传递给“项目知识库构建与管理Agent (PKBM)”进行存储，标记为“原始用户需求 v1.0”。
        4.  将记录的原始需求文本传递给“初步需求意图识别Agent”。
    *   **输入:** 用户提供的自然语言需求。
    *   **输出:** 原始需求文本的精确副本。

2.  **0.2 项目知识库构建与管理Agent (Project Knowledge Base Manager - PKBM):**
    *   **职责 (持续进行):**
        *   接收来自各个Agent的结构化信息和文档。
        *   为每条信息打上标签（如：`需求规格`、`架构决策`、`代码模块X`、`测试用例Y`、`人工审核意见Z`），并记录版本和时间戳。
        *   建立信息之间的关联（如：`代码模块X`实现了`需求点A`，`测试用例Y`用于验证`代码模块X`）。
        *   提供基于标签、关键词、关联性的精确信息检索服务给其他Agent。
    *   **输入/输出:** 持续接收和提供结构化数据。

3.  **0.3 初步需求意图识别Agent (Initial Intent Recognition Agent):**
    *   **任务:**
        1.  接收“原始用户需求文本”。
        2.  识别需求的核心动词和目标（例如：“创建”、“修改”、“修复”、“添加功能”）。
        3.  识别需求中提及的关键名词或实体（例如：“用户注册”、“购物车”、“API”、“数据库表”）。
        4.  输出一份包含“核心意图”和“关键实体列表”的初步分析报告。
        5.  将此报告存入PKBM，标记为“初步意图分析 v1.0”，并关联“原始用户需求 v1.0”。
        6.  将此报告传递给“项目类型与技术栈引导Agent”。
    *   **输入:** 原始用户需求文本。
    *   **输出:** 结构化的初步意图分析报告 (例如：`{ "intent": "create_new_feature", "entities": ["user_login", "oauth2"] }`)。

4.  **0.4 项目类型与技术栈引导Agent (Project Type & Tech Stack Elicitation Agent):**
    *   **任务:**
        1.  接收“初步意图分析报告”。
        2.  从PKBM调取项目历史信息（如果是已有项目）。
        3.  根据意图和实体，生成一系列针对性的问题，以获取或确认项目类型（Web应用、库、CLI工具等）、主要编程语言、核心框架、数据库类型等。问题示例：“您希望使用哪种编程语言来实现此功能？”“此项目是否基于特定的Web框架（如Flask, Django, Spring Boot）？”
        4.  通过“用户交互代理”（人工）向用户呈现这些问题。
        5.  接收用户的回答。
        6.  将问答记录和最终确认的项目类型及技术栈信息整理成结构化文档。
        7.  将此文档存入PKBM，标记为“项目元数据 v1.0”，并关联“初步意图分析 v1.0”。
        8.  将此文档传递给“详细需求澄清Agent”。
    *   **输入:** 初步意图分析报告，用户回答。
    *   **输出:** 结构化的项目元数据文档。

**阶段一：深度需求理解与规格化**

5.  **1.1 需求细节与边界条件挖掘Agent (Requirement Detail & Boundary Miner Agent):**
    *   **任务:**
        1.  接收“原始用户需求文本”和“项目元数据”。
        2.  从PKBM调取“初步意图分析报告”。
        3.  逐条分析原始需求中的每个句子/要点。
        4.  针对每个要点，生成旨在挖掘具体细节、非功能性需求（性能、易用性等）、边界条件、用户场景、预期行为和异常处理的问题。示例：“对于用户登录，密码错误次数达到多少次后应锁定账户？”“注册成功后，用户应被重定向到哪个页面？”“数据量预计有多大？”
        5.  将生成的问题列表通过“用户交互代理”呈现给用户。
        6.  接收用户的回答。
        7.  将问答记录整理并存入PKBM，标记为“需求澄清细节QA v1.0”。
        8.  将所有澄清后的细节传递给“用户故事生成Agent”和“验收标准定义Agent”。
    *   **输入:** 原始需求，项目元数据，用户回答。
    *   **输出:** 包含详细澄清问答的记录。

6.  **1.2 用户故事生成Agent (User Story Generation Agent):**
    *   **任务:**
        1.  接收来自“需求细节与边界条件挖掘Agent”的澄清后细节。
        2.  从PKBM调取“原始用户需求文本”和“项目元数据”。
        3.  根据“As a [type of user], I want [an action] so that [a benefit/value]”的模板，将澄清后的需求点转化为一系列用户故事。
        4.  确保每个用户故事都是独立的、可协商的、有价值的、可估计的、小的、可测试的（INVEST原则）。
        5.  输出用户故事列表（例如，Markdown或JSON格式）。
        6.  将用户故事列表存入PKBM，标记为“用户故事集 v1.0”。
        7.  将用户故事列表传递给“人工审核点1协调Agent”。
    *   **输入:** 澄清后的需求细节。
    *   **输出:** 结构化的用户故事列表。

7.  **1.3 验收标准定义Agent (Acceptance Criteria Definition Agent):**
    *   **任务:**
        1.  接收来自“需求细节与边界条件挖掘Agent”的澄清后细节。
        2.  从PKBM调取“用户故事集 v1.0”（由用户故事生成Agent刚生成）。
        3.  为每个用户故事，根据Gherkin语言格式 (Given-When-Then) 或其他清晰的、可验证的条件列表，定义详细的验收标准。
        4.  确保每个验收标准都是具体的、可衡量的、可实现的、相关的、有时间限制的（SMART原则，虽然时间限制可能由后续规划决定）。
        5.  输出与用户故事对应的验收标准集合。
        6.  将验收标准集合存入PKBM，标记为“验收标准集 v1.0”，并关联“用户故事集 v1.0”。
        7.  将验收标准集合传递给“人工审核点1协调Agent”。
    *   **输入:** 澄清后的需求细节，用户故事列表。
    *   **输出:** 结构化的验收标准集合。

8.  **1.4 需求规格文档编纂Agent (Requirements Specification Compiler Agent):**
    *   **任务:**
        1.  从PKBM调取“用户故事集 v1.0”和“验收标准集 v1.0”。
        2.  将用户故事和对应的验收标准整合成一份统一的、结构清晰的需求规格说明书文档 (例如，Markdown或PDF格式)。
        3.  文档应包含引言（项目目标简述）、用户故事列表、每个用户故事的详细验收标准。
        4.  将此文档存入PKBM，标记为“需求规格说明书 v1.0”。
        5.  将此文档传递给“人工审核点1协调Agent”。
    *   **输入:** 用户故事列表，验收标准集合。
    *   **输出:** 完整的需求规格说明书文档。

9.  **1.5 人工审核点1协调Agent (Human Review Point 1 Coordinator):**
    *   **任务:**
        1.  从PKBM接收“需求规格说明书 v1.0”（包含用户故事和验收标准）。
        2.  准备审核材料包，呈现给人工审核者（用户/产品经理）。
        3.  **审核要点清单（供人工参考）：**
            *   需求是否完整准确地反映了原始意图？
            *   用户故事是否清晰、独立、可测试？
            *   验收标准是否具体、可衡量，并能充分验证用户故事？
            *   是否存在遗漏的关键场景或边界条件？
            *   是否存在逻辑矛盾或不清晰之处？
        4.  接收人工审核结果（选项：批准通过 / 驳回并附带修改意见）。
        5.  如果“批准通过”：
            *   在PKBM中将“需求规格说明书 v1.0”标记为“已审核通过”。
            *   通知“系统架构方案提议Agent”开始工作。
        6.  如果“驳回”：
            *   将修改意见结构化记录，存入PKBM，标记为“需求审核反馈 v1.x”。
            *   根据反馈内容，决定是将任务重新路由回“需求细节与边界条件挖掘Agent”、“用户故事生成Agent”或“验收标准定义Agent”进行修改，并附上反馈意见。
    *   **输入:** 需求规格说明书，人工审核者的反馈。
    *   **输出:** 审核状态，（若驳回）结构化的修改意见。

**阶段二：架构设计与任务规划**
*(假设需求已通过审核)*

10. **2.1 技术选型建议Agent (Technology Selection Advisor Agent):**
    *   **任务:**
        1.  从PKBM调取“已审核通过的需求规格说明书 v1.0”和“项目元数据 v1.0”。
        2.  如果项目元数据中已明确技术栈，则跳过此步骤，直接将现有技术栈信息传递给后续Agent。
        3.  如果技术栈未定或需调整，根据需求（特别是NFRs，如性能、并发、安全性）、项目类型，生成一个包含2-3个候选技术栈（语言、框架、关键库、数据库）的建议列表。
        4.  为每个候选技术栈提供简要的优缺点分析、适用场景以及与项目需求的匹配度说明。
        5.  输出技术选型建议报告。
        6.  将报告存入PKBM，标记为“技术选型建议 v1.0”。
        7.  通过“用户交互代理”将建议报告提交给用户（或技术负责人）进行选择。
        8.  接收用户的最终技术选型决定。
        9.  将最终选定的技术栈更新到PKBM的“项目元数据”中（或创建新版本）。
        10. 将确认的技术栈信息传递给“高层组件划分Agent”。
    *   **输入:** 需求规格，项目元数据，用户选择。
    *   **输出:** 技术选型建议报告，更新后的项目元数据。

11. **2.2 高层组件划分Agent (High-Level Component Definition Agent):**
    *   **任务:**
        1.  从PKBM调取“已审核通过的需求规格说明书 v1.0”和已确认的“项目元数据”（含技术栈）。
        2.  根据需求和技术栈，识别出系统需要的主要高层模块/服务/组件（例如：用户认证服务、订单处理模块、产品目录API、数据持久化层、前端UI）。
        3.  为每个组件初步定义其核心职责。
        4.  输出高层组件列表及其职责描述。
        5.  将此列表存入PKBM，标记为“高层组件定义 v1.0”。
        6.  将此列表传递给“组件间接口草拟Agent”。
    *   **输入:** 需求规格，项目元数据。
    *   **输出:** 高层组件列表及职责描述。

12. **2.3 组件间接口草拟Agent (Component Interface Draft Agent):**
    *   **任务:**
        1.  从PKBM调取“高层组件定义 v1.0”。
        2.  分析组件间的依赖关系和数据流。
        3.  为需要交互的组件之间草拟初步的接口定义（例如：REST API端点、函数签名、消息队列主题和消息格式）。仅关注接口名称、主要参数和预期返回类型，无需详细数据结构。
        4.  输出组件间接口草案。
        5.  将草案存入PKBM，标记为“组件接口草案 v1.0”。
        6.  将草案传递给“架构图描述生成Agent”。
    *   **输入:** 高层组件定义。
    *   **输出:** 组件间接口草案。

13. **2.4 架构图描述生成Agent (Architecture Diagram Description Agent):**
    *   **任务:**
        1.  从PKBM调取“高层组件定义 v1.0”和“组件接口草案 v1.0”。
        2.  生成一段自然语言描述，该描述能够清晰地表达系统的高层架构，包括主要组件、它们之间的关系以及关键接口。（目标是让一个LLM能够基于此描述生成一个架构图，或让人能理解架构）。
        3.  （可选，如果LLM能力支持）尝试生成PlantUML或Mermaid等文本格式的图表描述。
        4.  输出架构图的文本描述。
        5.  将描述存入PKBM，标记为“架构图文本描述 v1.0”。
        6.  将描述传递给“架构设计文档编纂Agent”。
    *   **输入:** 高层组件定义，组件接口草案。
    *   **输出:** 架构图的文本描述。

14. **2.5 架构设计文档编纂Agent (Architecture Design Compiler Agent):**
    *   **任务:**
        1.  从PKBM调取“技术选型最终决定”（来自项目元数据）、“高层组件定义 v1.0”、“组件接口草案 v1.0”、“架构图文本描述 v1.0”。
        2.  将以上信息整合成一份高层架构设计文档。
        3.  文档应包含：技术选型及其理由、组件列表及其职责、组件间主要接口、架构图（或其文本描述）。
        4.  将文档存入PKBM，标记为“高层架构设计文档 v1.0”。
        5.  将文档传递给“人工审核点2协调Agent”。
    *   **输入:** 各架构设计元素。
    *   **输出:** 高层架构设计文档。

15. **2.6 人工审核点2协调Agent (Human Review Point 2 Coordinator):**
    *   **任务:**
        1.  从PKBM接收“高层架构设计文档 v1.0”。
        2.  准备审核材料包，呈现给人工审核者（技术负责人/架构师）。
        3.  **审核要点清单（供人工参考）：**
            *   技术选型是否合理、可行、符合项目需求和长期目标？
            *   组件划分是否清晰、职责是否单一、内聚是否高？
            *   组件间接口设计是否满足功能需求，是否考虑了可扩展性和可维护性？
            *   架构是否能支持需求的非功能性要求（性能、安全、伸缩性等）？
            *   是否存在明显的设计缺陷或风险点？
        4.  接收人工审核结果（批准通过 / 驳回并附带修改意见）。
        5.  如果“批准通过”：
            *   在PKBM中将“高层架构设计文档 v1.0”标记为“已审核通过”。
            *   通知“编码任务分解Agent”开始工作。
        6.  如果“驳回”：
            *   将修改意见结构化记录，存入PKBM，标记为“架构审核反馈 v1.x”。
            *   根据反馈，可能需要重新路由到“技术选型建议Agent”、“高层组件划分Agent”等。
    *   **输入:** 高层架构设计文档，人工审核反馈。
    *   **输出:** 审核状态，（若驳回）结构化的修改意见。

16. **2.7 编码任务分解Agent (Coding Task Breakdown Agent):**
    *   **任务:**
        1.  从PKBM调取“已审核通过的需求规格说明书 v1.0”和“已审核通过的高层架构设计文档 v1.0”。
        2.  将每个用户故事/功能点映射到架构中的一个或多个组件。
        3.  将大的功能点或组件实现进一步分解为更小的、可独立开发和测试的编码子任务（例如：实现用户模型的CRUD操作、设计登录API的请求/响应结构、编写密码加密工具类）。
        4.  为每个子任务明确其目标、预期产出（如某个类的实现、某个API端点）。
        5.  输出编码子任务列表。
        6.  将列表存入PKBM，标记为“编码子任务列表 v1.0”。
        7.  将列表传递给“任务依赖与顺序规划Agent”。
    *   **输入:** 需求规格，架构设计。
    *   **输出:** 编码子任务列表。

17. **2.8 任务依赖与顺序规划Agent (Task Dependency & Sequencing Agent):**
    *   **任务:**
        1.  从PKBM调取“编码子任务列表 v1.0”。
        2.  分析子任务之间的逻辑依赖关系（例如，必须先实现用户模型，才能实现用户注册API）。
        3.  根据依赖关系，确定一个合理的开发顺序或并行分组。
        4.  输出带有依赖关系和建议执行顺序的编码任务计划（例如，有向无环图描述或带优先级的列表）。
        5.  将计划存入PKBM，标记为“编码任务计划 v1.0”。
        6.  后续流程将按此计划逐个处理子任务。
    *   **输入:** 编码子任务列表。
    *   **输出:** 带有依赖和顺序的编码任务计划。

**阶段三：详细设计 (针对每个编码子任务循环)**
*(协调器会根据“编码任务计划 v1.0”逐个启动以下流程)*

18. **3.1 当前子任务上下文准备Agent (Current Subtask Context Preparer):**
    *   **任务:**
        1.  从“编码任务计划 v1.0”中获取当前待执行的子任务。
        2.  从PKBM调取与此子任务相关的全部上下文：
            *   对应的用户故事和验收标准。
            *   相关的架构设计部分（组件职责、接口定义）。
            *   项目元数据（技术栈、编码规范）。
            *   （如果是修改任务）现有代码库中相关的代码片段或文件结构（可能需要人工辅助定位并提供给PKBM）。
        3.  将这些上下文打包，传递给后续的详细设计Agent。
    *   **输入:** 当前子任务ID，PKBM。
    *   **输出:** 当前子任务的完整上下文包。

19. **3.2 API详细设计Agent (API Detailed Design Agent):** *(如果子任务涉及API)*
    *   **任务:**
        1.  接收“当前子任务上下文包”。
        2.  根据子任务需求和架构中的接口草案，详细设计API：
            *   精确的URL路径和HTTP方法。
            *   请求头、路径参数、查询参数的详细定义。
            *   请求体的JSON/XML Schema (或等效的详细结构描述)。
            *   响应体的JSON/XML Schema (或等效的详细结构描述) for 各种状态码 (200, 201, 400, 401, 403, 500等)。
            *   认证和授权机制说明。
        3.  输出API详细设计文档（例如，OpenAPI/Swagger片段或Markdown格式的详细描述）。
        4.  将文档存入PKBM，标记为“API详细设计_[子任务ID]_v1.0”。
    *   **输入:** 子任务上下文包。
    *   **输出:** API详细设计文档。

20. **3.3 数据模型详细设计Agent (Data Model Detailed Design Agent):** *(如果子任务涉及数据持久化或复杂数据结构)*
    *   **任务:**
        1.  接收“当前子任务上下文包”。
        2.  设计或更新数据库表结构：
            *   表名、列名、数据类型、约束（主键、外键、非空、唯一、检查约束）。
            *   索引建议。
            *   表间关系。
        3.  或设计程序内部使用的数据对象/类的属性和类型。
        4.  输出数据模型详细设计（例如，SQL DDL语句、类图的文本描述、JSON Schema）。
        5.  将设计存入PKBM，标记为“数据模型详细设计_[子任务ID]_v1.0”。
    *   **输入:** 子任务上下文包。
    *   **输出:** 数据模型详细设计。

21. **3.4 类与函数逻辑设计Agent (Class & Function Logic Design Agent):** *(如果子任务涉及具体业务逻辑实现)*
    *   **任务:**
        1.  接收“当前子任务上下文包”。
        2.  确定需要创建或修改的类和函数。
        3.  为每个关键类/函数：
            *   定义其职责。
            *   设计其公共接口（方法签名：名称、参数类型、返回类型）。
            *   用伪代码或详细的步骤描述其核心实现逻辑，包括主要算法、条件分支、循环、异常处理逻辑。
        4.  输出类与函数逻辑设计文档。
        5.  将文档存入PKBM，标记为“类函数逻辑设计_[子任务ID]_v1.0”。
    *   **输入:** 子任务上下文包。
    *   **输出:** 类与函数逻辑设计文档。

22. **3.5 文件与目录结构规划Agent (File & Directory Structure Planner Agent):**
    *   **任务:**
        1.  接收“当前子任务上下文包”。
        2.  从PKBM调取项目现有的（如果适用）文件结构和编码规范中关于结构的部分。
        3.  根据子任务的性质以及相关的API设计、数据模型设计、类函数设计，规划：
            *   需要创建的新文件名及其在项目中的完整路径。
            *   需要修改的现有文件名及其路径。
            *   是否需要创建新的目录。
        4.  确保规划的结构符合项目技术栈的最佳实践和编码规范。
        5.  输出文件和目录结构变更计划。
        6.  将计划存入PKBM，标记为“文件结构计划_[子任务ID]_v1.0”。
    *   **输入:** 子任务上下文包，相关详细设计。
    *   **输出:** 文件和目录结构变更计划。

23. **3.6 安全考量与检查点定义Agent (Security Considerations & Checkpoint Definer Agent):**
    *   **任务:**
        1.  接收“当前子任务上下文包”以及该子任务相关的所有详细设计文档（API、数据、逻辑）。
        2.  从PKBM调取项目安全规范、已知的安全漏洞模式 (如OWASP Top 10)。
        3.  针对当前子任务的设计，识别潜在的安全风险点（例如：SQL注入、XSS、CSRF、不安全的API暴露、敏感数据处理不当、权限控制缺失等）。
        4.  为每个风险点，提出具体的安全加固建议或必须在代码实现中包含的安全检查点/措施。
        5.  输出安全考量报告及检查点列表。
        6.  将报告存入PKBM，标记为“安全考量_[子任务ID]_v1.0”。
    *   **输入:** 子任务上下文包，所有相关详细设计。
    *   **输出:** 安全考量报告及检查点列表。

24. **3.7 详细设计汇总与指令生成Agent (Detailed Design Aggregation & Instruction Generator Agent):**
    *   **任务:**
        1.  接收当前子任务的所有详细设计文档（API、数据、逻辑、文件结构、安全考量）。
        2.  将这些设计整合成一份针对该子任务的《代码实现指导书》。
        3.  基于《代码实现指导书》，生成给“代码生成/修改Agent (CGMA)”或外部“Roo code LLM”的**极其具体、包含完整上下文的指令文本 (Prompt)**。该指令必须：
            *   明确是创建新文件还是修改现有文件（并提供完整路径）。
            *   如果修改，必须提供**原始代码的精确片段**（人工或辅助Agent从代码库获取并提供给PKBM）。
            *   清晰描述要实现的**功能逻辑、算法步骤、API行为、数据结构**。
            *   包含所有必要的**类名、函数签名、变量名约定**。
            *   强调必须遵循的**编码规范**（从PKBM调取）。
            *   列出必须实现的**安全检查点**。
            *   提供必要的**上下文代码片段**（如import语句、父类定义等，帮助LLM理解环境）。
            *   指定预期的**输出代码格式**（例如，一个完整的Python文件，或一个Java类中的特定方法）。
        4.  将《代码实现指导书》存入PKBM，标记为“实现指导书_[子任务ID]_v1.0”。
        5.  将生成的精确指令文本传递给“人工审核点3协调Agent”。
    *   **输入:** 子任务的所有详细设计文档，PKBM（编码规范、原始代码片段等）。
    *   **输出:** 《代码实现指导书》，给代码生成LLM的精确指令文本。

25. **3.8 人工审核点3协调Agent (Human Review Point 3 Coordinator):**
    *   **任务:**
        1.  接收为代码生成LLM准备的“精确指令文本”和对应的《代码实现指导书_[子任务ID]_v1.0》。
        2.  准备审核材料包，呈现给人工审核者（通常是开发人员）。
        3.  **审核要点清单（供人工参考）：**
            *   指令是否清晰、无歧义、完整？
            *   指令是否准确反映了《代码实现指导书》的所有要求？
            *   指令中包含的上下文信息（原始代码、规范、安全点）是否充分且正确？
            *   预期的代码输出描述是否明确？
            *   是否存在任何可能导致LLM误解或生成错误代码的表述？
        4.  接收人工审核结果（批准执行 / 驳回并附带修改指令的建议）。
        5.  如果“批准执行”：
            *   在PKBM中将“精确指令文本_[子任务ID]_v1.0”标记为“已审核待执行”。
            *   将指令文本传递给“代码生成/修改执行协调Agent”。
        6.  如果“驳回”：
            *   将修改建议存入PKBM。
            *   将任务路由回“详细设计汇总与指令生成Agent”进行修改。
    *   **输入:** 精确指令文本，实现指导书，人工审核反馈。
    *   **输出:** 审核状态，（若批准）待执行的指令文本。

**阶段四：代码生成与初步校验 (通过内部或外部LLM，针对每个子任务)**

26. **4.1 代码生成/修改执行协调Agent (CGMA Execution Coordinator):**
    *   **任务:**
        1.  接收“已审核待执行的精确指令文本_[子任务ID]_v1.0”。
        2.  **[手动交互点]** 将此指令文本复制粘贴到您指定的“Roo code LLM”或其他代码生成工具的输入界面。
        3.  触发“Roo code LLM”执行。
        4.  **[手动交互点]** 从“Roo code LLM”获取其生成的代码文本（或错误信息/状态）。
        5.  将“Roo code LLM”的原始输出（代码或错误信息）记录到PKBM，标记为“CGMA原始输出_[子任务ID]_v1.0”。
        6.  如果输出是代码，则将其传递给“代码基本语法与格式校验Agent”。如果输出是错误，则记录错误并可能需要人工介入或回溯。
    *   **输入:** 审核通过的精确指令文本。
    *   **输出:** CGMA生成的原始代码或错误信息。

27. **4.2 代码基本语法与格式校验Agent (Code Syntax & Basic Formatting Validator Agent):**
    *   **任务:**
        1.  接收“CGMA原始输出_[子任务ID]_v1.0”（假设是代码）。
        2.  从PKBM调取项目编码规范中关于格式化的部分和语言版本。
        3.  使用Linter（如ESLint, Pylint, Checkstyle）或编译器对代码进行基本的语法检查。
        4.  （可选，若LLM支持）尝试自动修复简单的格式问题。
        5.  输出校验结果报告（语法错误列表、格式问题列表）和（可能）初步格式化后的代码。
        6.  将校验报告和格式化代码存入PKBM，标记为“代码初步校验报告_[子任务ID]_v1.0”和“初步格式化代码_[子任务ID]_v1.0”。
        7.  如果存在严重语法错误导致无法进行后续步骤，标记问题并可能需要回溯到指令生成或人工介入。否则，将初步格式化代码传递给“静态代码分析Agent”。
    *   **输入:** CGMA原始输出代码。
    *   **输出:** 初步校验报告，初步格式化代码。

28. **4.3 静态代码分析Agent (Static Code Analyzer Agent):**
    *   **任务:**
        1.  接收“初步格式化代码_[子任务ID]_v1.0”。
        2.  从PKBM调取项目配置的静态分析规则集（例如，SonarQube规则子集、FindBugs规则）。
        3.  运行更深入的静态分析工具，检查潜在bug、代码异味、复杂度过高、未使用的变量/导入、简单的安全漏洞模式（如硬编码密码）。
        4.  输出详细的静态分析报告，包含问题描述、位置、严重级别和建议修复。
        5.  将报告存入PKBM，标记为“静态分析报告_[子任务ID]_v1.0”。
        6.  将报告和代码传递给“AI代码审查员Agent”。
    *   **输入:** 初步格式化代码。
    *   **输出:** 详细静态分析报告。

**阶段五：深度审查、测试与迭代 (针对每个子任务的产出)**

29. **5.1 AI代码审查员Agent (AI Code Reviewer Agent):**
    *   **任务:**
        1.  接收“初步格式化代码_[子任务ID]_v1.0”和“静态分析报告_[子任务ID]_v1.0”。
        2.  从PKBM调取该子任务的《实现指导书_[子任务ID]_v1.0》（包含所有设计要求、安全检查点）和“编码规范”。
        3.  **核心审查任务：**
            *   **功能符合性：** 代码是否实现了《实现指导书》中描述的所有功能点和逻辑？
            *   **设计遵循性：** 代码结构、类/函数设计是否与详细设计一致？API实现是否符合API设计？
            *   **规范遵循性：** 代码是否严格遵守了编码规范（命名、注释、风格等）？
            *   **可读性与可维护性：** 代码是否清晰易懂？是否存在过于复杂或难以维护的结构？
            *   **错误处理：** 是否恰当地处理了预期的异常和边界条件？
            *   **性能初步评估：** 是否存在明显的性能瓶颈（如不必要的循环、低效算法）？
            *   **安全性：** 是否落实了《实现指导书》中要求的安全检查点？是否存在静态分析未发现的、基于上下文的潜在安全问题？
        4.  针对每个发现的问题，提供具体的描述、代码位置、以及修改建议。
        5.  输出AI代码审查报告。
        6.  将报告存入PKBM，标记为“AI代码审查报告_[子任务ID]_v1.0”。
        7.  将报告、代码、静态分析报告传递给“人工审核点4协调Agent”。
    *   **输入:** 代码，静态分析报告，实现指导书，编码规范。
    *   **输出:** AI代码审查报告。

30. **5.2 人工审核点4协调Agent (Human Review Point 4 Coordinator - Code & AI Review):**
    *   **任务:**
        1.  接收“初步格式化代码_[子任务ID]_v1.0”、“静态分析报告_[子任务ID]_v1.0”和“AI代码审查报告_[子任务ID]_v1.0”。
        2.  准备审核材料包，呈现给人工审核者（开发人员/技术组长）。
        3.  **审核要点清单（供人工参考）：**
            *   AI生成的代码质量如何？是否基本可用？
            *   静态分析报告中的关键问题是否需要处理？
            *   AI代码审查报告是否准确？其提出的问题和建议是否合理？
            *   是否存在AI未能发现的关键问题（逻辑错误、深层设计缺陷、安全漏洞）？
            *   代码是否真正符合原始需求和设计意图？
        4.  接收人工审核结果（选项：批准进入测试 / 驳回并附带修改意见 / 直接手动修改代码并提交修改后版本）。
        5.  如果“批准进入测试”：
            *   在PKBM中将“初步格式化代码_[子任务ID]_v1.0”标记为“代码审核通过”。
            *   通知“单元测试用例生成Agent”开始工作。
        6.  如果“驳回”：
            *   将修改意见（针对代码或针对AI审查报告）结构化记录，存入PKBM。
            *   根据反馈，决定是重新生成指令（回溯到3.7）、要求CGMA重新生成（回溯到4.1）、或由AI代码审查员Agent尝试根据反馈生成修复建议。
        7.  如果“人工手动修改”：
            *   人工将修改后的代码提供给协调Agent。
            *   协调Agent将新代码存入PKBM，标记为“人工修正代码_[子任务ID]_v1.0”，并将其视为“代码审核通过”，通知测试。
    *   **输入:** 代码，各类报告，人工审核反馈/修改后的代码。
    *   **输出:** 审核状态，（若批准）进入测试的代码版本。

31. **5.3 单元测试用例生成Agent (Unit Test Case Generator Agent):**
    *   **任务:**
        1.  接收“代码审核通过”状态的代码（无论是AI生成后通过，还是人工修正后通过）。
        2.  从PKBM调取该子任务的《实现指导书》（特别是验收标准部分）、“类函数逻辑设计”、“API详细设计”以及项目使用的测试框架信息和测试编码规范。
        3.  针对代码中的每个主要函数/方法/类/API端点：
            *   生成覆盖正常路径的测试用例。
            *   生成覆盖已知边界条件的测试用例。
            *   生成覆盖预期异常处理的测试用例。
            *   确保测试用例的断言与《实现指导书》中的预期行为和验收标准一致。
        4.  输出单元测试用例代码文件（符合项目测试框架的格式）。
        5.  将测试用例代码存入PKBM，标记为“单元测试代码_[子任务ID]_v1.0”。
        6.  将测试用例代码和被测代码一起传递给“测试执行协调Agent”。
    *   **输入:** 审核通过的代码，实现指导书，设计文档，测试框架信息。
    *   **输出:** 单元测试用例代码。

32. **5.4 测试执行协调Agent (Test Execution Coordinator):**
    *   **任务:**
        1.  接收被测代码和“单元测试代码_[子任务ID]_v1.0”。
        2.  **[手动交互点]** 协助用户将单元测试代码集成到本地项目的测试套件中。
        3.  **[手动交互点]** 指导用户在本地环境中运行这些单元测试。
        4.  **[手动交互点]** 从用户处获取测试执行结果（例如，测试框架输出的报告文本，包含通过/失败数量、失败用例的名称、错误信息和堆栈跟踪）。
        5.  将测试结果报告原文存入PKBM，标记为“单元测试结果原始报告_[子任务ID]_v1.0”。
        6.  将报告传递给“测试结果分析与调试指引Agent”。
    *   **输入:** 被测代码，单元测试代码，用户提供的测试结果。
    *   **输出:** 单元测试结果原始报告。

33. **5.5 测试结果分析与调试指引Agent (Test Result Analyzer & Debugging Guide Agent):**
    *   **任务:**
        1.  接收“单元测试结果原始报告_[子任务ID]_v1.0”。
        2.  从PKBM调取相关的被测代码、单元测试代码、《实现指导书》。
        3.  分析测试报告：
            *   如果所有测试通过：在PKBM中标记子任务状态为“测试通过”，通知“子任务完成与集成准备Agent”。
            *   如果存在失败的测试用例：
                *   针对每个失败的用例，提取错误信息和堆栈跟踪。
                *   尝试将错误定位到被测代码或测试用例代码的具体行号。
                *   分析失败的可能原因（例如：逻辑错误、边界条件处理不当、测试用例断言错误、环境问题）。
                *   生成一份调试分析报告，包含：失败的测试列表、每个失败的详细错误、初步的原因分析、以及建议的调试步骤或修改方向（是修改被测代码还是修改测试用例）。
        4.  将调试分析报告（如果测试失败）存入PKBM，标记为“调试分析报告_[子任务ID]_v1.0”。
        5.  将报告传递给“人工审核点5协调Agent”。
    *   **输入:** 测试结果报告，相关代码和设计。
    *   **输出:** 子任务状态（测试通过/失败），（若失败）调试分析报告。

34. **5.6 人工审核点5协调Agent (Human Review Point 5 Coordinator - Debugging & Iteration):**
    *   **任务:**
        1.  接收“调试分析报告_[子任务ID]_v1.0”（如果测试失败）。
        2.  准备审核材料包（报告、相关代码），呈现给人工审核者（开发人员）。
        3.  **审核要点清单（供人工参考）：**
            *   AI对测试失败原因的分析是否准确？
            *   AI提出的调试建议或修改方向是否合理？
            *   确定问题根源是在产品代码、测试代码还是设计本身？
        4.  接收人工审核决策和指令（例如：确认是产品代码bug，请AI尝试修复；确认是测试用例问题，请AI修改测试；确认是设计问题，需要回溯到设计阶段；或人工直接修复并提交新代码/测试）。
        5.  如果需要AI修复/修改：
            *   将人工确认的问题和修改方向传递给“代码/测试修复指令生成Agent”。
        6.  如果人工直接修复：
            *   接收人工修改后的代码/测试，存入PKBM，然后重新触发“测试执行协调Agent”（返回5.4）。
        7.  如果需要回溯设计：
            *   在PKBM中记录问题，并通知中央协调器进行流程回溯。
    *   **输入:** 调试分析报告，人工反馈和指令。
    *   **输出:** 下一步行动指令（AI修复、人工修复、回溯）。

35. **5.7 代码/测试修复指令生成Agent (Code/Test Remediation Instruction Agent):**
    *   **任务:**
        1.  接收来自人工确认的“调试分析报告”和修复方向/要求。
        2.  从PKBM调取相关的代码（产品代码或测试代码）。
        3.  生成一条**极其具体**的指令给“代码生成/修改Agent (CGMA)”或外部“Roo code LLM”，用于修复已识别的bug或修改测试用例。指令应包含：
            *   要修改的文件名和精确的代码片段。
            *   清晰描述要修正的逻辑或行为。
            *   预期的正确行为。
        4.  将修复指令存入PKBM，标记为“修复指令_[子任务ID]_v1.x”。
        5.  将指令传递给“代码生成/修改执行协调Agent”（返回4.1），开始新一轮的代码生成->校验->审查->测试循环。
    *   **输入:** 确认的调试分析和修复要求，相关代码。
    *   **输出:** 给CGMA的精确修复指令。

**阶段六：集成、文档、交付与学习 (当一个或多个相关子任务“测试通过”后)**

36. **6.1 子任务完成与集成准备Agent (Subtask Completion & Integration Prep Agent):**
    *   **任务:**
        1.  当一个子任务在PKBM中被标记为“测试通过”时被激活。
        2.  检查“编码任务计划 v1.0”中该子任务的依赖关系。
        3.  如果所有前置依赖任务也都“测试通过”，则将此子任务的最终代码（在PKBM中标记为“最终版本代码_[子任务ID]”）标记为“待集成”。
        4.  通知“代码集成协调Agent”有一批新的“待集成”代码。
    *   **输入:** 子任务状态更新，编码任务计划。
    *   **输出:** “待集成”代码列表。

37. **6.2 代码集成协调Agent (Code Integration Coordinator):**
    *   **任务:**
        1.  接收一批“待集成”的代码模块/文件。
        2.  **[手动交互点]** 协助用户将这些新代码或修改后的代码合并到项目的主开发分支（或指定的目标分支）。
        3.  **[手动交互点]** 协助用户解决可能出现的合并冲突。
        4.  记录集成操作（哪些文件被合并，是否有冲突及如何解决）到PKBM，标记为“集成日志_[批次ID]_v1.0”。
        5.  集成完成后，通知“构建与冒烟测试Agent”。
    *   **输入:** 待集成代码列表，用户操作。
    *   **输出:** 集成操作日志。

38. **6.3 构建与冒烟测试Agent (Build & Smoke Test Agent):**
    *   **任务:**
        1.  在代码集成后被激活。
        2.  从PKBM调取项目构建脚本（pom.xml, package.json等）和构建说明。
        3.  **[手动交互点]** 协助用户执行完整的项目构建过程。
        4.  如果构建成功，**[手动交互点]** 协助用户执行一小组核心功能的快速冒烟测试（测试场景可能需要预先定义或由LLM根据需求和架构生成一个“冒烟测试计划”）。
        5.  收集构建结果（成功/失败，错误日志）和冒烟测试结果。
        6.  将结果存入PKBM，标记为“构建日志_[批次ID]_v1.0”和“冒烟测试报告_[批次ID]_v1.0”。
        7.  如果构建或冒烟测试失败，标记问题，可能需要回溯到代码修复或集成步骤。
        8.  如果通过，通知“技术文档更新Agent”和“最终人工验收协调Agent”。
    *   **输入:** 项目代码，构建脚本，（可选）冒烟测试计划，用户操作结果。
    *   **输出:** 构建和冒烟测试结果。

39. **6.4 技术文档更新Agent - 代码注释 (Technical Documentation Updater - Code Comments):**
    *   **任务:**
        1.  接收“构建与冒烟测试通过”的信号和涉及的已集成代码模块列表。
        2.  从PKBM调取这些代码模块的《实现指导书》和“编码规范”（关于注释的部分）。
        3.  为代码中的主要类、函数/方法、复杂逻辑块生成符合规范的、解释性的注释。
        4.  输出带有新增/更新注释的代码版本。
        5.  **[手动交互点]** 协助用户将这些注释应用到实际代码中。
        6.  将更新后的代码（带注释）在PKBM中标记为最终版本。
    *   **输入:** 已集成代码，实现指导书，编码规范。
    *   **输出:** 带注释的代码。

40. **6.5 技术文档更新Agent - API文档与README (Technical Documentation Updater - API Docs & README):**
    *   **任务:**
        1.  接收“构建与冒烟测试通过”的信号。
        2.  从PKBM调取所有相关的“API详细设计文档”、“高层架构设计文档”、“需求规格说明书”以及项目现有的API文档（如Swagger/OpenAPI文件）和README文件。
        3.  根据最新的代码和设计，更新或生成API文档。
        4.  更新项目README文件，包含新功能说明、安装/使用指南变更等。
        5.  生成本次迭代/变更的Changelog条目。
        6.  将更新后的文档（API文档、README、Changelog）存入PKBM。
    *   **输入:** 所有相关设计和需求文档，现有文档。
    *   **输出:** 更新后的API文档、README、Changelog。

41. **6.6 人工审核点6协调Agent (Human Review Point 6 Coordinator - Final Acceptance):**
    *   **任务:**
        1.  在构建和冒烟测试通过，且文档初步更新后被激活。
        2.  准备最终验收材料包：
            *   原始需求规格说明书。
            *   最终集成并测试通过的代码（或其访问方式）。
            *   更新后的技术文档（API文档、README）。
            *   冒烟测试报告。
            *   Changelog。
        3.  呈现给最终验收人（用户/产品负责人/测试负责人）。
        4.  **验收要点清单（供人工参考）：**
            *   交付的功能是否完整满足原始需求和验收标准？
            *   系统在冒烟测试中表现是否稳定？
            *   文档是否清晰、准确、完整？
            *   是否有任何未解决的重大问题或遗漏？
        5.  接收人工验收结果（批准发布 / 附条件批准 / 拒绝并说明原因）。
        6.  将验收结果和任何反馈记录到PKBM，标记为“最终验收报告_v1.0”。
        7.  如果“批准发布”，则流程结束。否则，根据反馈可能触发新的小型迭代或问题修复流程。
    *   **输入:** 最终交付物和报告，人工验收反馈。
    *   **输出:** 最终验收状态和报告。

42. **6.7 项目总结与知识沉淀Agent (Project Summary & Knowledge Distillation Agent):**
    *   **任务 (流程结束后或定期运行):**
        1.  从PKBM调取整个项目/迭代的所有数据：需求、设计、代码（各版本）、指令、审核反馈、测试结果、错误报告、修复记录等。
        2.  生成一份项目总结报告，包含：
            *   完成的功能点回顾。
            *   每个阶段LLM Agent的表现（例如，哪些Agent生成的初稿质量高，哪些Agent经常需要人工修正其输出）。
            *   人工审核点发现的主要问题类型和频率。
            *   整个流程中的瓶颈环节和耗时分析（基于时间戳）。
            *   从本次项目中可以提炼出的可复用知识/模式（例如，某个特定问题的优雅解决方案，某个易错点的警示）。
        3.  将总结报告和提炼的知识点存入PKBM，用于未来改进LLM的Prompt、微调LLM模型或优化流程本身。
    *   **输入:** PKBM中的全部项目数据。
    *   **输出:** 项目总结报告，可复用知识点。
